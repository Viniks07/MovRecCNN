{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b55143d",
   "metadata": {},
   "source": [
    "<p style=\"color: gray; \n",
    "          text-align: center;\n",
    "          font-size: 24px;\">\n",
    "Inicialização de Bibliotecas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25bc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from src import data_processing as dp\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a67cf",
   "metadata": {},
   "source": [
    "<p style=\"color: gray; \n",
    "          text-align: center;\n",
    "          font-size: 24px;\">\n",
    "Ajuste Foco Camera</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd04b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)\n",
    "cap.set(cv2.CAP_PROP_EXPOSURE, -1)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_AUTOFOCUS, 0)\n",
    "cap.set(cv2.CAP_PROP_FOCUS, 10)\n",
    "\n",
    "print(\"Exposição:\", cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "print(\"Foco:\", cap.get(cv2.CAP_PROP_FOCUS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ef696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positioning(frame,frame2): \n",
    "    if np.sum(frame[:160,:160]) > 0:\n",
    "        cv2.putText(frame2,                      \n",
    "            'Diag. Esq',           \n",
    "            (300, 470),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,   \n",
    "            1,                         \n",
    "            (0, 0, 255),                \n",
    "            2,                          \n",
    "            cv2.LINE_AA)    \n",
    "    elif np.sum(frame[:160,480:]):\n",
    "        cv2.putText(frame2,                      \n",
    "                'Diag. Dir',           \n",
    "                (300, 470),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,   \n",
    "                1,                         \n",
    "                (0, 0, 255),                \n",
    "                2,                          \n",
    "                cv2.LINE_AA)    \n",
    "    elif np.sum(frame[:160,160:480]) > 0:\n",
    "        cv2.putText(frame2,                      \n",
    "            'Cima',           \n",
    "            (300, 470),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,   \n",
    "            1,                         \n",
    "            (0, 0, 255),                \n",
    "            2,                          \n",
    "            cv2.LINE_AA)   \n",
    "    elif np.sum(frame[160:320,:160]) > 0:\n",
    "        cv2.putText(frame2,                      \n",
    "                'Esquerda',           \n",
    "                (300, 470),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,   \n",
    "                1,                         \n",
    "                (0, 0, 255),                \n",
    "                2,                          \n",
    "                cv2.LINE_AA)    \n",
    "    elif np.sum(frame[160:320,480:]) > 0:\n",
    "        cv2.putText(frame2,                      \n",
    "                'Direita',           \n",
    "                (300, 470),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,   \n",
    "                1,                         \n",
    "                (0, 0, 255),                \n",
    "                2,                          \n",
    "                cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "division = 16\n",
    "\n",
    "while True:\n",
    "    ret,frame_original = cap.read()\n",
    "    frame_original = f.mirroring(frame_original)\n",
    "    frame = frame_original.copy()\n",
    "    frame = f.gray_scale(frame)\n",
    "    frame = f.background_subtraction(cam_frame=frame,start_time=5,limiar=15)\n",
    "    frame,vec = f.down_sampling(frame,division=division)\n",
    "    frame = f.binarization(frame,limiar=5)\n",
    "    vec = f.binarization(vec,limiar=5)\n",
    "    original_view = frame_original.copy()\n",
    "    _,vec_positioning = f.bounding_box(frame,original_view,division=division)\n",
    "    positioning(frame,original_view)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    elif cv2.waitKey(1) & 0xFF == ord('1'):\n",
    "        f.background_subtraction.background = f.gray_scale(frame_original.copy())\n",
    "        frame_original = np.full_like(frame_original,255)\n",
    "\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('2'):\n",
    "        tensor = np.array(vec)\n",
    "        np.save(r'readme_media\\tensor.npy', tensor)\n",
    "        break\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # vec = vec[vec_positioning[0]:vec_positioning[1], vec_positioning[2]:vec_positioning[3]]\n",
    "\n",
    "    cv2.imshow('Original',original_view)\n",
    "    cv2.imshow('Visualizer',frame)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    cam = cv2.VideoCapture(r'readme_media\\wave.gif')\n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        \n",
    "        if cv2.waitKey(125) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_vizualizer = f.grid(frame)\n",
    "        cv2.imshow('Vid',frame_vizualizer)\n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "002a54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = cv2.imread(r'media/image/nina.png')\n",
    "bk = cv2.imread(r'media/image/nina_background_subtraction.png')\n",
    "bk = bk[4:-4,648:-4]\n",
    "bk = dp.gray_scale(bk)\n",
    "\n",
    "dilated = dp.dilate(dp.binarization(bk).copy())\n",
    "\n",
    "frames =110\n",
    "for i in range(frames):\n",
    "    mod = orig.copy()\n",
    "    if i>=30:\n",
    "        mod = dp.gray_scale(mod)\n",
    "    \n",
    "    if i>= 40:\n",
    "        mod = bk\n",
    "\n",
    "    if i>=50:\n",
    "        mod = dp.binarization(mod,limiar=5)\n",
    "\n",
    "    if i>=60:\n",
    "        mod = dilated\n",
    "\n",
    "    if i >=70:\n",
    "        _,mod = dp.down_sampling(mod,division=8)\n",
    "        mod = dp.binarization(mod)\n",
    "    if i >= 80:\n",
    "        _,mod = dp.bounding_box(mod,division=8)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    cv2.imshow('asd', mod)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e61ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "\n",
    "\n",
    "orig = cv2.imread(r'media/image/nina.png')\n",
    "bk = cv2.imread(r'media/image/nina_background_subtraction.png')\n",
    "bk = bk[4:-4,648:-4]\n",
    "bk = dp.gray_scale(bk)\n",
    "\n",
    "dilated = dp.dilate(dp.binarization(bk).copy())\n",
    "\n",
    "frames = 90\n",
    "gif_frames = []\n",
    "\n",
    "for i in range(frames):\n",
    "    mod = orig.copy()\n",
    "\n",
    "    if i >= 10:\n",
    "        mod = dp.gray_scale(mod)\n",
    "\n",
    "    if i >= 20:\n",
    "        mod = bk\n",
    "\n",
    "    if i >= 30:\n",
    "        mod = dp.binarization(mod, limiar=5)\n",
    "\n",
    "    if i >= 40:\n",
    "        mod = dilated\n",
    "\n",
    "    if i >= 50:\n",
    "        _, mod = dp.down_sampling(mod, division=8)\n",
    "        mod = dp.binarization(mod)\n",
    "\n",
    "    if i >= 60:\n",
    "        _, mod = dp.bounding_box(mod, division=8)\n",
    "\n",
    "\n",
    "    # Converte para RGB (Imageio usa RGB, OpenCV usa BGR)\n",
    "    if len(mod.shape) == 2:  # escala de cinza\n",
    "        mod_rgb = cv2.cvtColor(mod, cv2.COLOR_GRAY2RGB)\n",
    "        mod = np.pad(mod,pad_width=((4,4),(4,4)),mode='constant',constant_values=255)\n",
    "\n",
    "    else:\n",
    "        mod_rgb = cv2.cvtColor(mod, cv2.COLOR_BGR2RGB)\n",
    "        mod = np.pad(mod,pad_width=((4,4),(4,4),(0,0)),mode='constant',constant_values=255)\n",
    "\n",
    "\n",
    "    gif_frames.append(mod_rgb)\n",
    "\n",
    "\n",
    "    cv2.imshow('asd', mod)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Salva como GIF (10 fps = 100 ms por frame)\n",
    "imageio.mimsave('media/.bin/final_result.gif', gif_frames, duration=30,loop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "frames_pil = []\n",
    "for frame in frames_rgb:\n",
    "    frames_pil.append(Image.fromarray(frame))\n",
    "\n",
    "\n",
    "imageio.mimsave('media\\.bin\\gif.gif', frames_pil, duration=0.1, loop=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
